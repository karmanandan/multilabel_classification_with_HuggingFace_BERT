{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-24T05:02:01.630710Z","iopub.execute_input":"2023-08-24T05:02:01.631429Z","iopub.status.idle":"2023-08-24T05:02:01.646530Z","shell.execute_reply.started":"2023-08-24T05:02:01.631391Z","shell.execute_reply":"2023-08-24T05:02:01.645456Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q datasets\n!pip install -q transformers\n!pip install accelerate -U","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:02:01.649448Z","iopub.execute_input":"2023-08-24T05:02:01.650251Z","iopub.status.idle":"2023-08-24T05:02:41.092581Z","shell.execute_reply.started":"2023-08-24T05:02:01.650215Z","shell.execute_reply":"2023-08-24T05:02:41.091382Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.20.3)\nCollecting accelerate\n  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.20.3\n    Uninstalling accelerate-0.20.3:\n      Successfully uninstalled accelerate-0.20.3\nSuccessfully installed accelerate-0.22.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset,DatasetDict\nfrom transformers import (AutoTokenizer,AutoModelForSequenceClassification,\n                          TrainingArguments, Trainer)\nimport torch\n\ndataset = load_dataset(\"csv\", data_files=\"/kaggle/input/multilabel-classification-dataset/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:02:41.096239Z","iopub.execute_input":"2023-08-24T05:02:41.096579Z","iopub.status.idle":"2023-08-24T05:02:57.698062Z","shell.execute_reply.started":"2023-08-24T05:02:41.096551Z","shell.execute_reply":"2023-08-24T05:02:57.697149Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-c94e8593bfd251f3/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eb0a3ea34b84bea940ee3f25edb5035"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b58f0a6a0b5d4eb3a604d278fb45013c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-c94e8593bfd251f3/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9481030511554f8cacec2655b525d001"}},"metadata":{}}]},{"cell_type":"code","source":"ds_train_devtest = dataset['train'].train_test_split(test_size=0.2, seed=42)\nds_devtest = ds_train_devtest['test'].train_test_split(test_size=0.5, seed=42)\n\n\ndataset = DatasetDict({\n    'train': ds_train_devtest['train'],\n    'valid': ds_devtest['train'],\n    'test': ds_devtest['test']\n})","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:02:57.699795Z","iopub.execute_input":"2023-08-24T05:02:57.700510Z","iopub.status.idle":"2023-08-24T05:02:57.766939Z","shell.execute_reply.started":"2023-08-24T05:02:57.700473Z","shell.execute_reply":"2023-08-24T05:02:57.766047Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:02:57.770024Z","iopub.execute_input":"2023-08-24T05:02:57.770390Z","iopub.status.idle":"2023-08-24T05:02:57.777542Z","shell.execute_reply.started":"2023-08-24T05:02:57.770362Z","shell.execute_reply":"2023-08-24T05:02:57.776432Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['ID', 'TITLE', 'ABSTRACT', 'Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance'],\n        num_rows: 16777\n    })\n    valid: Dataset({\n        features: ['ID', 'TITLE', 'ABSTRACT', 'Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance'],\n        num_rows: 2097\n    })\n    test: Dataset({\n        features: ['ID', 'TITLE', 'ABSTRACT', 'Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance'],\n        num_rows: 2098\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:02:57.779375Z","iopub.execute_input":"2023-08-24T05:02:57.779774Z","iopub.status.idle":"2023-08-24T05:02:57.791499Z","shell.execute_reply.started":"2023-08-24T05:02:57.779741Z","shell.execute_reply":"2023-08-24T05:02:57.790141Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'ID': 11567,\n 'TITLE': 'Classification of rank two Lie conformal algebras',\n 'ABSTRACT': '  We give a complete classification (up to isomorphism) of Lie conformal\\nalgebras which are free of rank two as $\\\\C[\\\\partial]$-modules, and determine\\ntheir automorphism groups.\\n',\n 'Computer Science': 0,\n 'Physics': 0,\n 'Mathematics': 1,\n 'Statistics': 0,\n 'Quantitative Biology': 0,\n 'Quantitative Finance': 0}"},"metadata":{}}]},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:02:57.793459Z","iopub.execute_input":"2023-08-24T05:02:57.793844Z","iopub.status.idle":"2023-08-24T05:02:57.802559Z","shell.execute_reply.started":"2023-08-24T05:02:57.793812Z","shell.execute_reply":"2023-08-24T05:02:57.801456Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'train': (16777, 9), 'valid': (2097, 9), 'test': (2098, 9)}"},"metadata":{}}]},{"cell_type":"code","source":"dataset.column_names","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:02:57.804357Z","iopub.execute_input":"2023-08-24T05:02:57.804685Z","iopub.status.idle":"2023-08-24T05:02:57.816245Z","shell.execute_reply.started":"2023-08-24T05:02:57.804654Z","shell.execute_reply":"2023-08-24T05:02:57.815301Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'train': ['ID',\n  'TITLE',\n  'ABSTRACT',\n  'Computer Science',\n  'Physics',\n  'Mathematics',\n  'Statistics',\n  'Quantitative Biology',\n  'Quantitative Finance'],\n 'valid': ['ID',\n  'TITLE',\n  'ABSTRACT',\n  'Computer Science',\n  'Physics',\n  'Mathematics',\n  'Statistics',\n  'Quantitative Biology',\n  'Quantitative Finance'],\n 'test': ['ID',\n  'TITLE',\n  'ABSTRACT',\n  'Computer Science',\n  'Physics',\n  'Mathematics',\n  'Statistics',\n  'Quantitative Biology',\n  'Quantitative Finance']}"},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.remove_columns(['ID','TITLE'])","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:02:57.818614Z","iopub.execute_input":"2023-08-24T05:02:57.819486Z","iopub.status.idle":"2023-08-24T05:02:57.834764Z","shell.execute_reply.started":"2023-08-24T05:02:57.819453Z","shell.execute_reply":"2023-08-24T05:02:57.833832Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:02:57.839742Z","iopub.execute_input":"2023-08-24T05:02:57.840194Z","iopub.status.idle":"2023-08-24T05:02:57.850150Z","shell.execute_reply.started":"2023-08-24T05:02:57.840109Z","shell.execute_reply":"2023-08-24T05:02:57.849155Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'ABSTRACT': '  We give a complete classification (up to isomorphism) of Lie conformal\\nalgebras which are free of rank two as $\\\\C[\\\\partial]$-modules, and determine\\ntheir automorphism groups.\\n',\n 'Computer Science': 0,\n 'Physics': 0,\n 'Mathematics': 1,\n 'Statistics': 0,\n 'Quantitative Biology': 0,\n 'Quantitative Finance': 0}"},"metadata":{}}]},{"cell_type":"code","source":"# create labels column\ncols = dataset[\"train\"].column_names\ndataset = dataset.map(lambda x : {\"labels\": [x[c] for c in cols if c != \"ABSTRACT\"]})\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:02:57.854496Z","iopub.execute_input":"2023-08-24T05:02:57.854759Z","iopub.status.idle":"2023-08-24T05:03:01.019670Z","shell.execute_reply.started":"2023-08-24T05:02:57.854730Z","shell.execute_reply":"2023-08-24T05:03:01.018759Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16777 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"822cdb329c1f4233b1ddcdfe38009675"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2097 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae69a13d8f534a22a5382054ed14e80c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2098 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9fa5f707bfa404b8b96ab5a96870a54"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['ABSTRACT', 'Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance', 'labels'],\n        num_rows: 16777\n    })\n    valid: Dataset({\n        features: ['ABSTRACT', 'Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance', 'labels'],\n        num_rows: 2097\n    })\n    test: Dataset({\n        features: ['ABSTRACT', 'Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance', 'labels'],\n        num_rows: 2098\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'][2]","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:01.020969Z","iopub.execute_input":"2023-08-24T05:03:01.021442Z","iopub.status.idle":"2023-08-24T05:03:01.032757Z","shell.execute_reply.started":"2023-08-24T05:03:01.021403Z","shell.execute_reply":"2023-08-24T05:03:01.031408Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'ABSTRACT': '  We describe a communication game, and a conjecture about this game, whose\\nproof would imply the well-known Sensitivity Conjecture asserting a polynomial\\nrelation between sensitivity and block sensitivity for Boolean functions. The\\nauthor defined this game and observed the connection in Dec. 2013 - Jan. 2014.\\nThe game and connection were independently discovered by Gilmer, Koucký, and\\nSaks, who also established further results about the game (not proved by us)\\nand published their results in ITCS \\'15 [GKS15].\\nThis note records our independent work, including some observations that did\\nnot appear in [GKS15]. Namely, the main conjecture about this communication\\ngame would imply not only the Sensitivity Conjecture, but also a stronger\\nhypothesis raised by Chung, Füredi, Graham, and Seymour [CFGS88]; and,\\nanother related conjecture we pose about a \"query-bounded\" variant of our\\ncommunication game would suffice to answer a question of Aaronson, Ambainis,\\nBalodis, and Bavarian [AABB14] about the query complexity of the \"Weak Parity\"\\nproblem---a question whose resolution was previously shown by [AABB14] to\\nfollow from a proof of the Chung et al. hypothesis.\\n',\n 'Computer Science': 1,\n 'Physics': 0,\n 'Mathematics': 0,\n 'Statistics': 0,\n 'Quantitative Biology': 0,\n 'Quantitative Finance': 0,\n 'labels': [1, 0, 0, 0, 0, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"model_ckpt = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt, problem_type=\"multi-label-classification\")","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:01.034442Z","iopub.execute_input":"2023-08-24T05:03:01.034793Z","iopub.status.idle":"2023-08-24T05:03:02.391260Z","shell.execute_reply.started":"2023-08-24T05:03:01.034759Z","shell.execute_reply":"2023-08-24T05:03:02.390292Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d60e612cffcf4b31b31235a074c2e6a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c4a4220115b4f7e85d5d7a4cf4b1c0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1eeb8288cac4d0b9a22db2ff80536ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"144bbacb228449ccaac1fbfc59729c44"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_and_encode(examples):\n    return tokenizer(examples[\"ABSTRACT\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:02.392935Z","iopub.execute_input":"2023-08-24T05:03:02.393356Z","iopub.status.idle":"2023-08-24T05:03:02.398910Z","shell.execute_reply.started":"2023-08-24T05:03:02.393319Z","shell.execute_reply":"2023-08-24T05:03:02.397426Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"cols = dataset[\"train\"].column_names\ncols.remove(\"labels\")\nds_enc = dataset.map(tokenize_and_encode, batched=True, remove_columns=cols)\nds_enc","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:02.400611Z","iopub.execute_input":"2023-08-24T05:03:02.400968Z","iopub.status.idle":"2023-08-24T05:03:18.762533Z","shell.execute_reply.started":"2023-08-24T05:03:02.400934Z","shell.execute_reply":"2023-08-24T05:03:18.761025Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5daaae41edad47eaabe4567c051aac27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"923dc4c5d6814ce5971295a0e90942cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9388e6c9c09043eeb5420d8f78d973ae"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 16777\n    })\n    valid: Dataset({\n        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2097\n    })\n    test: Dataset({\n        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2098\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"ds_enc['train']['labels'][0]","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:18.764118Z","iopub.execute_input":"2023-08-24T05:03:18.764479Z","iopub.status.idle":"2023-08-24T05:03:18.894044Z","shell.execute_reply.started":"2023-08-24T05:03:18.764445Z","shell.execute_reply":"2023-08-24T05:03:18.893081Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[0, 0, 1, 0, 0, 0]"},"metadata":{}}]},{"cell_type":"code","source":"# cast label IDs to floats\nds_enc.set_format(\"torch\")\nds_enc = (ds_enc\n          .map(lambda x : {\"float_labels\": x[\"labels\"].to(torch.float)}, remove_columns=[\"labels\"])\n          .rename_column(\"float_labels\", \"labels\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:18.895266Z","iopub.execute_input":"2023-08-24T05:03:18.895592Z","iopub.status.idle":"2023-08-24T05:03:43.247411Z","shell.execute_reply.started":"2023-08-24T05:03:18.895559Z","shell.execute_reply":"2023-08-24T05:03:43.246482Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16777 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f26a0da9226466c8061bbaa0eb9df2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2097 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"784b374c8f1848a0ae5051385410b053"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2098 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7df95af4f7724d908dbafc63dccbcdff"}},"metadata":{}}]},{"cell_type":"code","source":"num_labels = 6\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_ckpt, num_labels=num_labels, problem_type='multi_label_classification').to('cuda')","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:43.251743Z","iopub.execute_input":"2023-08-24T05:03:43.254338Z","iopub.status.idle":"2023-08-24T05:03:52.504056Z","shell.execute_reply.started":"2023-08-24T05:03:43.254298Z","shell.execute_reply":"2023-08-24T05:03:52.502970Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f8c9311f2af4bf3a8d723116bde27f7"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"ds_enc[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:52.505564Z","iopub.execute_input":"2023-08-24T05:03:52.505926Z","iopub.status.idle":"2023-08-24T05:03:52.546425Z","shell.execute_reply.started":"2023-08-24T05:03:52.505891Z","shell.execute_reply":"2023-08-24T05:03:52.545572Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([  101,  2057,  2507,  1037,  3143,  5579,  1006,  2039,  2000, 11163,\n         19539,  1007,  1997,  4682, 23758,  2389, 11208,  2015,  2029,  2024,\n          2489,  1997,  4635,  2048,  2004,  1002,  1032,  1039,  1031,  1032,\n          7704,  1033,  1002,  1011, 14184,  1010,  1998,  5646,  2037,  8285,\n         19539,  2967,  1012,   102]),\n 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n 'labels': tensor([0., 0., 1., 0., 0., 0.])}"},"metadata":{}}]},{"cell_type":"code","source":"args = TrainingArguments(\n    '/kaggle/working/',\n    evaluation_strategy = \"epoch\",\n    num_train_epochs=5,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:52.547870Z","iopub.execute_input":"2023-08-24T05:03:52.548242Z","iopub.status.idle":"2023-08-24T05:03:52.555420Z","shell.execute_reply.started":"2023-08-24T05:03:52.548209Z","shell.execute_reply":"2023-08-24T05:03:52.554433Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model=model, args = args,\n                  train_dataset = ds_enc[\"train\"],\n                  eval_dataset = ds_enc[\"test\"],\n                  tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:52.556909Z","iopub.execute_input":"2023-08-24T05:03:52.557282Z","iopub.status.idle":"2023-08-24T05:03:52.574336Z","shell.execute_reply.started":"2023-08-24T05:03:52.557249Z","shell.execute_reply":"2023-08-24T05:03:52.573405Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T05:03:52.577427Z","iopub.execute_input":"2023-08-24T05:03:52.577727Z","iopub.status.idle":"2023-08-24T06:08:30.875072Z","shell.execute_reply.started":"2023-08-24T05:03:52.577703Z","shell.execute_reply":"2023-08-24T06:08:30.874098Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230824_050454-mrndgon6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/team_karma/huggingface/runs/mrndgon6' target=\"_blank\">ethereal-forest-3</a></strong> to <a href='https://wandb.ai/team_karma/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/team_karma/huggingface' target=\"_blank\">https://wandb.ai/team_karma/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/team_karma/huggingface/runs/mrndgon6' target=\"_blank\">https://wandb.ai/team_karma/huggingface/runs/mrndgon6</a>"},"metadata":{}},{"name":"stderr","text":"You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5245' max='5245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5245/5245 1:02:57, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.189400</td>\n      <td>0.184107</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.144200</td>\n      <td>0.167039</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.107800</td>\n      <td>0.190839</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.070300</td>\n      <td>0.220338</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.042200</td>\n      <td>0.240762</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5245, training_loss=0.1156929901603066, metrics={'train_runtime': 3877.973, 'train_samples_per_second': 21.631, 'train_steps_per_second': 1.353, 'total_flos': 1.6816351628021148e+16, 'train_loss': 0.1156929901603066, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T06:08:30.876815Z","iopub.execute_input":"2023-08-24T06:08:30.878037Z","iopub.status.idle":"2023-08-24T06:09:01.947139Z","shell.execute_reply.started":"2023-08-24T06:08:30.877994Z","shell.execute_reply":"2023-08-24T06:09:01.946140Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [132/132 00:30]\n    </div>\n    "},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.24076198041439056,\n 'eval_runtime': 31.0462,\n 'eval_samples_per_second': 67.577,\n 'eval_steps_per_second': 4.252,\n 'epoch': 5.0}"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'][700]","metadata":{"execution":{"iopub.status.busy":"2023-08-24T06:14:13.132729Z","iopub.execute_input":"2023-08-24T06:14:13.133125Z","iopub.status.idle":"2023-08-24T06:14:13.144218Z","shell.execute_reply.started":"2023-08-24T06:14:13.133065Z","shell.execute_reply":"2023-08-24T06:14:13.142375Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"{'ABSTRACT': '  In this paper, we introduce the concept of a virtual machine with\\ngraph-organised memory as a versatile backend for both explicit-state and\\nabstraction-driven verification of software. Our virtual machine uses the LLVM\\nIR as its instruction set, enriched with a small set of hypercalls. We show\\nthat the provided hypercalls are sufficient to implement a small operating\\nsystem, which can then be linked with applications to provide a\\nPOSIX-compatible verification environment. Finally, we demonstrate the\\nviability of the approach through a comparison with a more\\ntraditionally-designed LLVM model checker.\\n',\n 'Computer Science': 1,\n 'Physics': 0,\n 'Mathematics': 0,\n 'Statistics': 0,\n 'Quantitative Biology': 0,\n 'Quantitative Finance': 0,\n 'labels': [1, 0, 0, 0, 0, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"# text = '  In some planetary systems the orbital periods of two of its members present a\\ncommensurability, usually known by mean-motion resonance. These resonances\\ngreatly enhance the mutual gravitational influence of the planets. As a\\nconsequence, these systems present uncommon behaviours and their motions need\\nto be studied with specific methods. Some features are unique and allow us a\\nbetter understanding and characterisation of these systems. Moreover,\\nmean-motion resonances are a result of an early migration of the orbits in an\\naccretion disk, so it is possible to derive constraints on their formation.\\nHere we review the dynamics of a pair of resonant planets and explain how their\\norbits evolve in time. We apply our results to the HD45365 planetary system\\n'\ntext = '  In this paper, we introduce the concept of a virtual machine with\\ngraph-organised memory as a versatile backend for both explicit-state and\\nabstraction-driven verification of software. Our virtual machine uses the LLVM\\nIR as its instruction set, enriched with a small set of hypercalls. We show\\nthat the provided hypercalls are sufficient to implement a small operating\\nsystem, which can then be linked with applications to provide a\\nPOSIX-compatible verification environment. Finally, we demonstrate the\\nviability of the approach through a comparison with a more\\ntraditionally-designed LLVM model checker.\\n'\nencoding = tokenizer(text, return_tensors=\"pt\")\nencoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n\noutputs = trainer.model(**encoding)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T06:14:30.311326Z","iopub.execute_input":"2023-08-24T06:14:30.311715Z","iopub.status.idle":"2023-08-24T06:14:30.352046Z","shell.execute_reply.started":"2023-08-24T06:14:30.311682Z","shell.execute_reply":"2023-08-24T06:14:30.350842Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"logits = outputs.logits\nlogits.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-24T06:14:30.787200Z","iopub.execute_input":"2023-08-24T06:14:30.787560Z","iopub.status.idle":"2023-08-24T06:14:30.795696Z","shell.execute_reply.started":"2023-08-24T06:14:30.787530Z","shell.execute_reply":"2023-08-24T06:14:30.794741Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 6])"},"metadata":{}}]},{"cell_type":"code","source":"# apply sigmoid + threshold\nsigmoid = torch.nn.Sigmoid()\nprobs = sigmoid(logits.squeeze().cpu())\npredictions = np.zeros(probs.shape)\npredictions[np.where(probs >= 0.5)] = 1\npredictions\n# turn predicted id's into actual label names\nans_cols = cols[1:]\npredicted_labels = [ans_cols[idx] for idx, label in enumerate(predictions) if label == 1.0]\nprint(predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T06:20:56.295065Z","iopub.execute_input":"2023-08-24T06:20:56.295824Z","iopub.status.idle":"2023-08-24T06:20:56.305494Z","shell.execute_reply.started":"2023-08-24T06:20:56.295787Z","shell.execute_reply":"2023-08-24T06:20:56.304494Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"['Computer Science']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}